{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4319,"status":"ok","timestamp":1697496122429,"user":{"displayName":"Poetry","userId":"07093435344447892703"},"user_tz":-180},"id":"1Un7GSC9n25O","outputId":"d94bc4e4-b7ac-4829-ed57-49cea790db63"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"1Un7GSC9n25O"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1697496122431,"user":{"displayName":"Poetry","userId":"07093435344447892703"},"user_tz":-180},"id":"qpnO1c1Wn4_l","outputId":"ad04e969-1221-47e6-95ab-2b0af2b3c51d"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Project6\n"]}],"source":["import os\n","os.chdir('/content/drive/MyDrive/Project6/')\n","!pwd"],"id":"qpnO1c1Wn4_l"},{"cell_type":"code","execution_count":null,"metadata":{"id":"W1_S34hNnSI0"},"outputs":[],"source":["%matplotlib inline"],"id":"W1_S34hNnSI0"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HV5d7pgJU2co","executionInfo":{"status":"ok","timestamp":1697497667286,"user_tz":-180,"elapsed":228766,"user":{"displayName":"Poetry","userId":"07093435344447892703"}},"outputId":"b3ddbf97-8faa-4053-b38c-4844618eb447"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","2023-10-16 23:04:00.494399: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-10-16 23:04:01.523609: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","[INFO] loading dataset...\n","[[606, 6596], [606, 6596, 6597], [606, 6596, 6597, 152], [606, 6596, 6597, 152, 142], [606, 6596, 6597, 152, 142, 4], [606, 6596, 6597, 152, 142, 4, 6598], [606, 6596, 6597, 152, 142, 4, 6598, 2400], [606, 6596, 6597, 152, 142, 4, 6598, 2400, 6599], [606, 6596, 6597, 152, 142, 4, 6598, 2400, 6599, 48], [606, 6596, 6597, 152, 142, 4, 6598, 2400, 6599, 48, 606]]\n","18743\n","2023-10-16 23:04:08.774404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-16 23:04:08.812775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-16 23:04:08.813069: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-16 23:04:08.813980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-16 23:04:08.814280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-16 23:04:08.814542: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-16 23:04:09.756852: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-16 23:04:09.757207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-16 23:04:09.757479: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-10-16 23:04:09.757620: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-10-16 23:04:09.757663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13692 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 2000, 10)          187430    \n","                                                                 \n"," lstm (LSTM)                 (None, 100)               44400     \n","                                                                 \n"," dropout (Dropout)           (None, 100)               0         \n","                                                                 \n"," dense (Dense)               (None, 18743)             1893043   \n","                                                                 \n","=================================================================\n","Total params: 2124873 (8.11 MB)\n","Trainable params: 2124873 (8.11 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","[INFO] training model...\n","2023-10-16 23:04:11.639560: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2781536172 exceeds 10% of free system memory.\n","2023-10-16 23:04:14.168211: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2781536172 exceeds 10% of free system memory.\n","Epoch 1/5\n","2023-10-16 23:04:19.808715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8900\n","2023-10-16 23:04:20.123898: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7d51ef0c7670 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-10-16 23:04:20.123947: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-10-16 23:04:20.129756: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2023-10-16 23:04:20.272089: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","145/145 [==============================] - ETA: 0s - loss: 9.4882 - accuracy: 0.01502023-10-16 23:05:03.186290: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 695440272 exceeds 10% of free system memory.\n","2023-10-16 23:05:03.806235: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 695440272 exceeds 10% of free system memory.\n","\n","Epoch 1: saving model to model_lstm_2/training_1/cp.ckpt\n","145/145 [==============================] - 52s 324ms/step - loss: 9.4882 - accuracy: 0.0150 - val_loss: 9.7914 - val_accuracy: 0.0162\n","Epoch 2/5\n","145/145 [==============================] - ETA: 0s - loss: 9.0259 - accuracy: 0.0156\n","Epoch 2: saving model to model_lstm_2/training_1/cp.ckpt\n","145/145 [==============================] - 43s 295ms/step - loss: 9.0259 - accuracy: 0.0156 - val_loss: 10.1305 - val_accuracy: 0.0162\n","Epoch 3/5\n","145/145 [==============================] - ETA: 0s - loss: 8.9284 - accuracy: 0.0156\n","Epoch 3: saving model to model_lstm_2/training_1/cp.ckpt\n","145/145 [==============================] - 40s 277ms/step - loss: 8.9284 - accuracy: 0.0156 - val_loss: 10.3158 - val_accuracy: 0.0162\n","Epoch 4/5\n","145/145 [==============================] - ETA: 0s - loss: 8.8562 - accuracy: 0.0156\n","Epoch 4: saving model to model_lstm_2/training_1/cp.ckpt\n","145/145 [==============================] - 37s 257ms/step - loss: 8.8562 - accuracy: 0.0156 - val_loss: 10.4918 - val_accuracy: 0.0162\n","Epoch 5/5\n","145/145 [==============================] - ETA: 0s - loss: 8.7986 - accuracy: 0.0156\n","Epoch 5: saving model to model_lstm_2/training_1/cp.ckpt\n","145/145 [==============================] - 36s 250ms/step - loss: 8.7986 - accuracy: 0.0156 - val_loss: 10.6835 - val_accuracy: 0.0162\n","Figure(1200x400)\n"]}],"source":["!python train_model_lstm.py --dataset process_data/new_dataset.csv --row 200 --epochs 5 --batch_size 256\n"],"id":"HV5d7pgJU2co"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Wrp0ggeLXHi"},"outputs":[],"source":[],"id":"2Wrp0ggeLXHi"},{"cell_type":"code","source":[],"metadata":{"id":"T4_lKT8Gv8jt"},"id":"T4_lKT8Gv8jt","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"}},"nbformat":4,"nbformat_minor":5}